name: E2E HyperShift

on:
  push:
    branches: [main]
    paths:
      - 'kagenti/**'
      - 'charts/**'
      - 'deployments/**'
      - '.github/**'
  # Use pull_request_target for fork PRs to access secrets
  # SECURITY: First-time contributors require maintainer approval via GitHub UI
  pull_request_target:
    branches: [main]
    paths:
      - 'kagenti/**'
      - 'charts/**'
      - 'deployments/**'
      - '.github/**'
  workflow_dispatch:
    inputs:
      cluster_name:
        description: 'Custom cluster name (optional)'
        required: false
        default: ''
      ocp_version:
        description: 'OpenShift version'
        required: false
        default: '4.20.10'
      skip_destroy:
        description: 'Skip cluster destruction (for debugging)'
        required: false
        type: boolean
        default: false

# Only allow one run per PR to avoid resource conflicts
# When a new commit is pushed, the old run is cancelled but cleanup step runs first
concurrency:
  group: e2e-hypershift-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

env:
  # Cluster suffix - deterministic per PR to enable cleanup-first strategy
  # For PRs: pr<number> (e.g., pr529) - same name for all commits in a PR
  # For push to main: run number (each push gets fresh cluster)
  # For workflow_dispatch: user-provided or run_number
  CLUSTER_SUFFIX: ${{ inputs.cluster_name || (github.event.pull_request.number && format('pr{0}', github.event.pull_request.number)) || github.run_number }}
  OCP_VERSION: ${{ inputs.ocp_version || '4.20.10' }}

jobs:
  e2e-ocp-kagenti-operator:
    name: e2e (OCP, Kagenti Operator)
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6
        with:
          # For pull_request_target, checkout the PR head (not base branch)
          ref: ${{ github.event.pull_request.head.sha || github.sha }}

      - name: Validate secrets are configured
        run: bash .github/scripts/hypershift/ci/00-validate-secrets.sh
        env:
          HYPERSHIFT_MGMT_KUBECONFIG: ${{ secrets.HYPERSHIFT_MGMT_KUBECONFIG }}
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          PULL_SECRET: ${{ secrets.PULL_SECRET }}
          BASE_DOMAIN: ${{ secrets.BASE_DOMAIN }}
          MANAGED_BY_TAG: ${{ secrets.MANAGED_BY_TAG }}
          HCP_ROLE_NAME: ${{ secrets.HCP_ROLE_NAME }}

      - name: Setup credentials
        run: bash .github/scripts/hypershift/ci/10-setup-credentials.sh
        env:
          HYPERSHIFT_MGMT_KUBECONFIG: ${{ secrets.HYPERSHIFT_MGMT_KUBECONFIG }}
          MANAGED_BY_TAG: ${{ secrets.MANAGED_BY_TAG }}
          PULL_SECRET: ${{ secrets.PULL_SECRET }}

      - name: Install tools
        run: bash .github/scripts/hypershift/ci/20-install-tools.sh
        env:
          OCP_VERSION: ${{ env.OCP_VERSION }}

      - name: Setup Go
        uses: actions/setup-go@v6
        with:
          go-version: '1.23'

      - name: Build hcp CLI from source
        run: bash .github/scripts/hypershift/ci/30-build-hcp-cli.sh

      - name: Clone hypershift-automation
        run: bash .github/scripts/hypershift/ci/40-clone-hypershift-automation.sh

      - name: Verify management cluster access
        run: bash .github/scripts/hypershift/ci/50-verify-mgmt-access.sh

      - name: Cleanup any existing cluster (from cancelled runs)
        run: bash .github/scripts/hypershift/ci/55-cleanup-existing-cluster.sh
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          MANAGED_BY_TAG: ${{ secrets.MANAGED_BY_TAG }}
          HCP_ROLE_NAME: ${{ secrets.HCP_ROLE_NAME }}
          CLUSTER_SUFFIX: ${{ env.CLUSTER_SUFFIX }}

      - name: Create HyperShift cluster
        id: create-cluster
        run: bash .github/scripts/hypershift/create-cluster.sh "${{ env.CLUSTER_SUFFIX }}"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          MANAGED_BY_TAG: ${{ secrets.MANAGED_BY_TAG }}
          HCP_ROLE_NAME: ${{ secrets.HCP_ROLE_NAME }}
          BASE_DOMAIN: ${{ secrets.BASE_DOMAIN }}
          OCP_VERSION: ${{ env.OCP_VERSION }}

      - name: Deploy Kagenti
        if: success()
        run: bash .github/scripts/hypershift/ci/70-deploy-kagenti.sh
        env:
          KUBECONFIG: ${{ steps.create-cluster.outputs.cluster_kubeconfig }}

      - name: Run E2E tests
        if: success()
        run: bash .github/scripts/hypershift/ci/80-run-e2e-tests.sh
        env:
          KUBECONFIG: ${{ steps.create-cluster.outputs.cluster_kubeconfig }}
          KAGENTI_CONFIG_FILE: deployments/envs/ocp_values.yaml

      - name: Collect cluster info on failure
        if: failure()
        run: bash .github/scripts/hypershift/ci/85-collect-failure-info.sh
        env:
          KUBECONFIG: ${{ steps.create-cluster.outputs.cluster_kubeconfig }}

      - name: Destroy HyperShift cluster
        # Always try to destroy cluster, even if create-cluster step failed
        # The destroy script gracefully handles "cluster not found" cases
        # Note: Using !inputs.skip_destroy instead of != true for compatibility with pull_request_target
        if: ${{ always() && !inputs.skip_destroy }}
        run: bash .github/scripts/hypershift/destroy-cluster.sh "${{ env.CLUSTER_SUFFIX }}"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          MANAGED_BY_TAG: ${{ secrets.MANAGED_BY_TAG }}
          HCP_ROLE_NAME: ${{ secrets.HCP_ROLE_NAME }}

      - name: Summary
        if: always()
        run: bash .github/scripts/hypershift/ci/99-summary.sh
        env:
          CLUSTER_NAME: ${{ steps.create-cluster.outputs.cluster_name }}
          CLUSTER_SUFFIX: ${{ env.CLUSTER_SUFFIX }}
          MANAGED_BY_TAG: ${{ secrets.MANAGED_BY_TAG }}
          OCP_VERSION: ${{ env.OCP_VERSION }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
          CREATE_OUTCOME: ${{ steps.create-cluster.outcome }}
          SKIP_DESTROY: ${{ inputs.skip_destroy || 'false' }}
